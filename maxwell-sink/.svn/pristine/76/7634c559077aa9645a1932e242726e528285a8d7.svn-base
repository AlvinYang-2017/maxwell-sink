package com.cimc.maxwell.sink.db;

import com.alibaba.fastjson.JSON;
import com.cimc.maxwell.sink.MySqlSinkConfig;
import com.cimc.maxwell.sink.filter.ConditionFilter;
import com.cimc.maxwell.sink.row.ExportRowMap;
import com.cimc.maxwell.sink.row.RowMap;
import org.apache.commons.lang3.StringUtils;
import org.apache.kafka.connect.errors.ConnectException;
import org.apache.kafka.connect.sink.SinkRecord;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.sql.Connection;
import java.sql.DriverManager;
import java.sql.SQLException;
import java.sql.Statement;
import java.util.*;

/**
 * Created by 00013708 on 2017/8/9.
 */
public final class MysqlDbWriter {
    private static final Logger log = LoggerFactory.getLogger(MysqlDbWriter.class);

    private static final Logger datalog = LoggerFactory.getLogger("datalog");
    private static final int DB_CONNECT_MAX_RETIRES = 3;
    private static final int DB_RETRY_BACKOFF_MS = 5000;
    private static final int CONNECTION_VALIDATE_TIMEOUT_S = 5;//秒

    private Connection connection;

    private List<String> sqlBuffer = null;
    private final MySqlSinkConfig config;

    private final SqlAssembler assembler;

    private final Map<String, String> topicDbMap;

    private final ConditionFilter filter;

    private final Set<Long> xidSet;

    public MysqlDbWriter(MySqlSinkConfig config) {
        this.config = config;
        sqlBuffer = new ArrayList<>();
        this.topicDbMap = initTopicDbMap(config.topicTargetDB);
        this.assembler = new SqlAssembler(config.tablesPK);
        this.filter = new ConditionFilter(config.filterConditions);
        xidSet = new HashSet<>();
    }

    /**
     * 消费的主题和导入的db对应关系
     *
     * @param topicTargetDB example:estation.db_ez.t_parcel:db_ez,estation.db_ez.t_box:db_ez
     * @return example: {"estation.db_ez.t_parcel" : "db_ez","estation.db_ez.t_box" : "db_ez"}
     */
    private Map<String, String> initTopicDbMap(String topicTargetDB) {
        if (StringUtils.isEmpty(topicTargetDB)) {
            log.warn("topicTargetDb config null");
            throw new IllegalArgumentException("topicTargetDb config null");
        }
        final Map<String, String> map = new HashMap<>();
        String[] topicDbPairs = topicTargetDB.split(",");
        for (String pair : topicDbPairs) {//有重复代码，可以统一处理
            String[] arr = pair.split(":");
            String topic = arr[0];
            String db = arr[1];
            map.put(topic, db);
        }
        log.info("initTopicDbMap success.values:{}", JSON.toJSONString(map));
        return map;
    }

    //首先尝试获取一个连接，如果连接是非法的新建一个连接，此连接不释放，作为一个Cache的连接
    public synchronized Connection getValidConnection() throws SQLException {
        if (connection != null && connection.isValid(CONNECTION_VALIDATE_TIMEOUT_S)) {
            return connection;
        } else {
            connection = createNewConnection();
            return connection;
        }
    }

    private Connection createNewConnection() throws SQLException {
        int attempts = 0;
        while (attempts < DB_CONNECT_MAX_RETIRES) {
            try {
                Class.forName(config.mysqlDriver);
                Connection connection = DriverManager.getConnection(config.mysqlUrl, config.mysqlUsername,
                        config.mysqlPassword);
                return connection;
            } catch (ClassNotFoundException e) {
                log.error(e.getMessage(), e);
                throw new ConnectException(e);
            } catch (SQLException e) {
                log.error(e.getMessage(), e);
                attempts++;
                if (attempts > DB_CONNECT_MAX_RETIRES) {
                    throw e;
                }
                log.info("connect to database failed,has retried:{} times,retry backoff:{}", attempts, DB_RETRY_BACKOFF_MS);
                try {
                    Thread.sleep(DB_RETRY_BACKOFF_MS);
                } catch (InterruptedException e1) {
                }
            }
        }
        return null;
    }


    public final void write2Buffer(final String sql) throws SQLException {
        if (StringUtils.isEmpty(sql)) {
            return;
        }
        if (sqlBuffer == null) {
            sqlBuffer = new ArrayList<>(config.mysqlBatchSize);
        }
        sqlBuffer.add(sql);
        if (sqlBuffer.size() >= config.mysqlBatchSize) {
            flush(sqlBuffer);
            sqlBuffer.clear();
        }
    }


    public void batchWrite(final Collection<SinkRecord> records) throws SQLException {
        if (records == null || records.isEmpty()) {
            return;
        }
        for (SinkRecord record : records) {
            String topic = record.topic();
            String val = (String) record.value();
            log.info("key:{},value:{},topic:{},partition:{},offset:{}", record.key(), record.value(), topic, record.kafkaPartition(), record.kafkaOffset());
            RowMap rowMap = JSON.parseObject(val, RowMap.class);
            //用作去重
            Long xid = rowMap.getXid();
            if (xidSet.contains(xid)) {
                log.warn("duplicate xid:{},rowMap:{}", xid, rowMap.toString());
                continue;
            } else {
                xidSet.add(xid);
            }
            /**数据过滤**/
            if (filter.match(rowMap)) {
                //将新老数据输出到指定文件
                ExportRowMap exportRowMap = new ExportRowMap(rowMap, assembler.getPk(rowMap.getDatabase(), rowMap.getTable()));
                datalog.info(exportRowMap.toString());

                String sql = assembler.getSql(setTargetDb(topic, rowMap));
                if (StringUtils.isNotEmpty(sql)) {
                    write2Buffer(sql);
                }
            }
        }
    }

    private RowMap setTargetDb(final String topic, final RowMap rowMap) {
        if (StringUtils.isEmpty(topic) || rowMap == null) {
            return null;
        }
        //判断是否要根据topic替换目标数据库
        if (topicDbMap.containsKey(topic)) {
            String targetDb = topicDbMap.get(topic);
            log.info("topic:{},set database: {} to {}", topic, rowMap.getData(), targetDb);
            rowMap.setDatabase(targetDb);
        }
        return rowMap;
    }


    public void flush(final List<String> sqlBatch) throws SQLException {
        if (sqlBatch == null || sqlBatch.isEmpty()) {
            return;
        }
        Connection connection = getValidConnection();
        connection.setAutoCommit(false);

        Statement statement = connection.createStatement();
        for (String sql : sqlBatch) {
            statement.addBatch(sql);
        }
        int[] updateCountArr = statement.executeBatch();
        if (updateCountArr.length != sqlBatch.size()) {
            throw new ConnectException(String.format("updateCountArr size:(%d) not equals to sqlBatch size:(%d)", updateCountArr.length, sqlBatch.size()));
        }
        connection.commit();
        statement.close();
    }

    public synchronized void closeQuietly() {
        try {
            if (connection != null && !connection.isClosed()) {
                connection.close();
            }
        } catch (SQLException e) {
            log.error(e.getMessage(), e);
        } finally {//强制释放
            connection = null;
        }
    }

    //从maxwell db中查询出来，废弃
    /*private Map<String,Map<String,String>> initTablesPk(String topics) {
        if(StringUtils.isEmpty(topics)){
            throw new IllegalArgumentException("topics empty");
        }
        Map<String,Map<String,String>>  map = new HashMap<>();
        String[] topicArr = topics.split(",");
        for(String topic:topicArr){
            String[] arr = topic.split(",");
            String dbName = arr[1];
            String tbName = arr[2];
            //从数据库中查询出对应的pk值
            String sql = "select pk from `databases` d,`tables` t where d.id = t.database_id and d.`name` = ? and t.`name` = ?";
        }
    }*/


    /*    public int write(String sql) throws SQLException {
        if (StringUtils.isEmpty(sql)) {
            return 0;
        }
        Connection connection = getValidConnection();

        PreparedStatement ps = connection.prepareStatement(sql);
        log.info("Execute SQL:{}", sql);
        int updateCount = ps.executeUpdate();
        ps.close();
        return updateCount;
    }*/
}
